---
layout: post
title:  "sql on hadoop之hive存储结构的发展史以及性能优化的方向"
date:   2014-06-11
categories: 
- Notes 
tags:
- 分布式系统与计算
---
     hive是facebook与2009年开源的一个建立在hadoop之上的大数据分析仓库，并提供类似sql的接口hql.用户输入的sql进过hive的语法语义分析之后依次生成抽象语法书---逻辑查询计划--物理查询计划--最后转变为多个相互依赖的mapreduce job提交给jobtracker进行处理。从
这里可以看出**hive是建立在mr框架之上的，所以hive的定位就在于对海量的离线数据进行分析，而且是适合OLAP而非OLTP**，不用于时下正火的google dremel的开源实现impala&&drill 以及建立在内存计算框架spark之上的shark（这两个东西我会在下一篇文章中说一下）。
hive和它们做对比是不合理的。

    自从hive开源至今已经发布到了0.13版本，出现很大的变化。主要体现在多个方面：
    1.我所熟悉的存储结构的变化，从textfile到sequencefile到rcfile再到orcfile以及我们自己开发的存储结构fosf。
    
    2.sql解析器的优化，比如说map side join 以及start join优化等；
    
    3.底层计算引擎的变化，tez计算框架的出现，尚且不稳定；
    
    4.解析方式的变化，从一行一行解析到并行多行的解析，也不稳定。
    
    5.acid这种事务机制的low level支持。
    
    6.前面所说的暂且认为是性能的纵向提高，那么hcatlog这种方便管理元数据的姑且认为是功能的横向扩展吧。
    
    下面我先重点说一下存储结构的演化。
    
    textfile和sequencfile都属于按行存储的格式，区别在于后者的存储更加紧凑，节省了一定的存储空间。按行存储的结构主要有两个缺点。前面说过Hive定位于OLAP，那么行存储结构对于一个普通select　a,b from tablec 这样的查询而言会加载太多的查询无关的列到内存里，比如说一个table有100列，我们只需要查询其中少数列，但是加载的时候，我们是需要把整行的数据全部加载到内存里之后才组合出查询相关的列，由此可以看出，行存储加载了太多查询无关的数据到内存里。
    这是缺点之一，缺点之二是相对于列存储的每一个列的数据类型相同而言，行存储很难有高效的压缩效果。
    
    
    于是，便有了列存储的RCFile的出现。其实严格上老说RCFile是行存储和列存储相结合的混合存储方式，对于一张表，我们首先是水平划分对个segment，这样做的目的是为了保证每一行元祖的多个属性列存放在同一个block，这样在查询时元祖重构的时候
    没有跨节点的网络开销。在水平划分的基础上，对于每一个segment，Rcfile则是按列来存储，起性能的提升正是前面所说的行存储的两个缺点。
    
    R然而，优化并没有停止。。我们在查询的时候虽然做到了只把查询相关的列加载进入到内存里，对于select　a,b from tablec where c>100  而言，rcfile就是把abc三列全部加载到内存之后再做c>100这个判断条件的筛选。看到这里你可能就会想，
    为何不只把c列先加载到内存里进行判断，得出满足条件的行号，然后再加载ab列相应的数据进来不就行了么。。对的，但是hive以前的执行逻辑据我所知是是吧abc全部加载到内存之后再判断filter的。所以这里就需要实现filter pushdown机制（这个在后面的hive已经实现了）。
    
    好了，实现了这个机制之后，我们只需要加载c列的全部数据到内存里，然和再加载需要的ab列到内存里。。。。。那能不能再优化一点呢。其实可以考虑为每一个的基本粒度page建立一个索引，粗糙的记录这个page

   的最大值和最小值，这样的话，针对c>100这样的过滤条件，我们只需要先拿这个page的最小值和最大值进行比较（比较结构有postive，negative以及rough三种）。其中rough是性能最差的情况。比如说这个page的最大值是150，最小值是50,也就是说这个page有一部分
   数据满足filter一部分不满足，称之为rough。那么我们就只能把这个page全部数据加载进来再逐行暴力比价。这也就是我为何称之为粗糙索引的原因，实际情况下要避免rough的出现（后面我会讨论这个）。
   
   好了，上述思想的实现者其实有三个，一个是orc，一个是我们team的存储结构的fosf，还有一个就是twitter的parquet，其实这三个存储结构开始的时间点差不多，但结果还是不一样的，orc已经成为了hive最新的高效的存储结构，而我们team的fosf则实在是没落，后来parquet也成为了hive官方支持的存储结构。。这原因嘛是多方面的，确实很懊悔。
   
  然而，事情并没有结束
