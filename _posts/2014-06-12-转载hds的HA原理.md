---
layout: post
title:  "（转载）hdfs的HA的实现策略"
date:   2014-06-12
categories: 
- Notes 
tags:
- 分布式系统与计算
---

谢谢http://yanbohappy.sinaapp.com/?p=205#comments 这位数据科学家的文章

当前HDFS HA的解决方案主要有以下几种：**Linux HA, VMware FT, shared NAS+NFS, BookKeeper, QJM/Quorum Journal Manager, BackupNode等**

目前普遍采用的是shard NAS+NFS，因为简单易用，但是需要提供一个HA的共享存储设备。而社区已经把基于QJM/Quorum Journal Manager的方
案merge到trunk了，clouderea提供的发行版中也包含了这个feature，这种方案也是社区在未来发行版中默认的HA方案。本文从代码的角度分
析这种方案的实现。

关于HDFS源代码中HA机制的整体框架实现，每个DN要向Active和Standby NN来report block，这样才能保证hot standby等等类似的问题，可以参考前面的文章:
http://yanbohappy.sinaapp.com/?p=50  和 http://yanbohappy.sinaapp.com/?p=55 。

在HA具体实现方法不同的情况下，HA框架的流程是一致的。不一致的就是如何存储和管理日志。在Active NN和Standby NN之间要有个共享的存
储日志的地方，Active NN把EditLog写到这个共享的存储日志的地方，Standby NN去读取日志然后执行，这样Active和Standby NN内存中的
HDFS元数据保持着同步。一旦发生主从切换Standby NN可以尽快接管Active NN的工作（虽然要经历一小段时间让原来Standby追上原来的
Active，但是时间很短）。

说到这个共享的存储日志的地方，目前采用最多的就是用共享存储NAS+NFS。缺点有：1）这个存储设备要求是HA的，不能挂掉；2）主从切换时
需要fencing方法让原来的Active不再写EditLog，否则的话会发生**brain-split**，因为如果不阻止原来的Active停止向共享存储写EditLog，
那么就有两个Active NN了，这样就会破坏HDFS的元数据了。对于防止brain-split问题，在QJM出现之前，常见的方法就是在发生主从切换的时候，
把共享存储上存放EditLog的文件夹对原来的Active的写权限拿掉，那么就可以保证同时至多只有一个Active NN，防止了破坏HDFS元数据。

QJM的基本原理就是用2N+1台JournalNode存储EditLog，**每次写数据操作有大多数（>=N+1）返回成功时即认为该次写成功**，数据不会丢失了。
当然这个算法所能容忍的是最多有N台机器挂掉，如果多于N台挂掉，这个算法就失效了。**这个原理是基于Paxos算法**（感觉难懂）的，可以参考 
http://en.wikipedia.org/wiki/Paxos_(computer_science) 。

**那么为什么不使用NAS+NFS共享存储呢？这是我对这篇文章最关心的。用QJM的方式来实现HA的主要好处有：**

**1不需要配置额外的高共享存储**，这样对于基于commodity hardware的云计算数据中心来说，降低了复杂度和维护成本；

**2**不在需要单独配置fencing实现，因为QJM本身内置了fencing的功能；

**3不存在Single Point Of Failure**；

**4系统鲁棒性的程度是可配置的（QJM基于Paxos算法，所以如果配置2N+1台JournalNode组成的集群，能容忍最多N台机器挂掉）**

5 QJM中存储日志的JournalNode不会因为其中一台的延迟而影响整体的延迟，而且也不会因为JournalNode的数量增多而影响性能（因为NN向JournalNode发送日志是并行的）。
