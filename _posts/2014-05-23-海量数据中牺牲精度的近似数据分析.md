---
layout: post
title:  "海量数据中牺牲精度的近似数据分析"
date:   2014-05-23 
categories: 
- Notes 
tags:
- 海量数据分析处理
---
为什么要写这篇文章呢？我在一次阿里巴巴的技术沙龙上听到了花名离哲的架构师讲到了阿里在做的即时计算平台grudua,涉及到的技术很多，其中有一点特别吸引我，当初提到了**grudua用到了牺牲一定精度的Top K策略**。我相信大家对Top K 算法都有一定了解，但是开销很大，而牺牲精度的Topk算法咱还是第一次听说。所以回来就查了一些资料。

发现有两篇博客写的很不错，学习了。

http://highscalability.com/blog/2012/4/5/big-data-counting-how-to-count-a-billion-distinct-objects-us.html

http://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/

http://www.cnblogs.com/fxjwind/p/3289221.html

http://blog.codinglabs.org/articles/algorithms-for-cardinality-estimation-part-i.html

